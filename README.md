# Standardized Metadata

This is an initiative within the [CDF SIG Interoperability](https://github.com/cdfoundation/sig-interoperability).

# Volunteers

* Tracy Miranda, CDF
* Steve Taylor, DeployHub
* James Strachan, CloudBees
* Fatih Degirmenci, Ericsson Software Technology

# Introduction

The tools and technologies that are used to construct CI/CD pipelines and the pipelines themselves produce lots of data. Organizations collect, store, and use this data in various ways to get value out of it.

One of the challenges when it comes to metadata is that there is no standardized way for CI/CD tools and technologies with regards to what metadata to produce and consume. In addition to what to produce and consume, how such metadata could be consumed and produced is yet another topic to think about. One aspect of that is already being looked at within CDF - [Events in CI/CD Workstream](https://github.com/cdfoundation/sig-interoperability/tree/master/workstreams/events_in_cicd).

It's true that there are initiatives across various open source projects to align the way this is done such as in-toto, Kubernetes, Jenkins X, and Tekton. However, this topic requires a holistic approach to identify the needs and challenges first, followed by analysing existing efforts to explore possibilities to streamline how this is done either based on existing efforts or by combining them to come up with a standard way collaboratively.

# Scope

The scope of this work could perhaps be best described by using an imaginary pipeline on a relatively high level.

* Commit: Commit data on SCM systems such as SHA, commit message
* Build & Packaging: Artifact related data produced by build systems and artifact repositories such as artifact checksum, version
* Test: Test results produced by test tools and frameworks such as pass/fail rate, logs
* Security and Vulnerability Scanning: Analysis results generated by security and vulnerability tools such as existing issues and level of criticality
* Promotion: The data used for taking the verdict to promote a certain version to next stage, e.g. staging, production
* Deployment: The data produced upon deployment of the artifact

As one can notice, the pipeline itself and the tools and technologies employed by different stages within pipeline generate huge amount of data.

* commit SHA
* commit message
* artifact checksum
* artifact version
* test pass/fail rate
* test logs
* list of vulnerabilities
* confidence level
* promotion metadata
* release metadata
* deployment status

As highlighted above, this data could be used in different ways both real-time and historical purposes.
Some examples to this are

* real-time use: take certain decisions based on generated metadata in order to determine whether the next stages within the pipeline should proceed or not
* historical use: generation of bill of materials for a specific version of the deliverable

Based on the example above, here are some of the questions that could help setting the scope

* types of metadata to consider
* the means to produce/consume/transport the metadata
    * events is one of the ways to transport the metadata which is currently being worked on in [Events in CI/CD Workstream](https://github.com/cdfoundation/sig-interoperability/tree/master/workstreams/events_in_cicd)
* how metadata is used
* analysis of existing efforts in order not to reinvent the wheel

# Existing Efforts

* eBay Metadata
* Ortelius Hermetic Manifest/Helm Chart
* [Tekton Chains](https://github.com/tektoncd/chains)
* [in-toto](https://in-toto.io/specs/)
* Jenkins X Metadata Example
* Input from Events in CI/CD workstream
* [SPDX Package Specificiation](https://spdx.github.io/spdx-spec/3-package-information/)
* [SPDX Relationship Specification](https://spdx.github.io/spdx-spec/7-relationships-between-SPDX-elements/)
* [Eiffel Protocol](https://github.com/eiffel-community/eiffel) with a vocabulary for metadata
* [The SIG Interoperability Vocabulary initiative](https://github.com/cdfoundation/sig-interoperability/blob/master/docs/vocabulary.md)

## Jenkins X Releases

[Jenkins X](https://jenkins-x.io/v3/about/) includes a [Release](https://github.com/jenkins-x/jx-api/blob/master/pkg/apis/jenkins.io/v1/types_release.go#L16) CRD which includes the metadata for an individual release. 

It includes details of where in git the release came from, the version, SHA, changelog, release notes along with commits, issues, PRs included.

This CRD is then included in the helm chart thats generated so it can be shipped with the actual application. Longer term we could look at integrating this into the helm chart metadata too maybe.

e.g. 

```bash 
kubectl get release
NAME             NAME       VERSION   GIT URL
nodey545-1.0.1   nodey545   v1.0.1    https://github.com/jstrachan/nodey545
```

Here's an example released resource...
```yaml 
apiVersion: jenkins.io/v1
kind: Release
metadata:
  name: nodey545-1.0.1
spec:
  commits:
  - author:
      email: jenkins-x@googlegroups.com
      name: jenkins-x-bot
    branch: master
    committer:
      email: jenkins-x@googlegroups.com
      name: jenkins-x-bot
    message: |
      chore: release 1.0.1
    sha: 5e09f11287f68843759ee3b6c31b88c4f95745b6
  - author:
      email: jenkins-x@googlegroups.com
      name: jenkins-x-bot
    branch: master
    committer:
      email: jenkins-x@googlegroups.com
      name: jenkins-x-bot
    message: |
      chore: add variables
    sha: 5a5926c40cd1482cab4d12136c3b8c4852057769
  - author:
      email: james.strachan@gmail.com
      name: James Strachan
    branch: master
    committer:
      email: james.strachan@gmail.com
      name: James Strachan
    message: |
      chore: Jenkins X build pack
    sha: c7730637f441f9045297c1e20dccf8842e2d14b1
  gitHttpUrl: https://github.com/jstrachan/nodey545
  gitOwner: jstrachan
  gitRepository: nodey545
  name: nodey545
  releaseNotesURL: https://github.com/jstrachan/nodey545/releases/tag/v1.0.1
  version: v1.0.1
 ```
